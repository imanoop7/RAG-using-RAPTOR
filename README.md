# RAG using RAPTOR

!RAG and RAPTOR

This repository explores the integration of RAG (Retrieval-Augmented Generation) with RAPTOR (Robustly Optimized Pre-trained Transformer) models. RAG combines the power of retrieval-based methods with language generation, while RAPTOR provides robust and efficient language understanding.

## Overview

- **What is RAG?**: RAG is a framework that enhances language models by incorporating information from a retriever. It retrieves relevant context before generating responses.
- **Why Combine with RAPTOR?**: RAPTOR is designed for robust and efficient inference, making it an excellent choice for RAG applications.
- **Getting Started**: Follow these steps to use RAG with RAPTOR:

    1. **Install Dependencies**: Set up RAG and RAPTOR libraries.
    2. **Prepare Data**: Create a retriever index using RAPTOR.
    3. **Integrate RAG**: Use RAG to combine retriever results with RAPTOR-generated responses.
    4. **Fine-Tuning**: Customize RAG behavior based on your specific use case.

## Examples

- **Question Answering**: Use RAG to retrieve relevant passages and generate concise answers.
- **Content Summarization**: Combine RAG's retrieval with RAPTOR's summarization capabilities.

## License

This project is licensed under the MIT License - see the LICENSE file for details.

---

_This repository was inspired by the synergy of retrieval and generation models. Happy experimenting!_ üìöüîçü§ñ

 
_Have implemented this with help of -
 https://github.com/langchain-ai/langchain/blob/master/cookbook/RAPTOR.ipynb
 and
 https://github.com/parthsarthi03/raptor/blob/master/raptor/cluster_tree_builder.py
 and
 https://github.com/run-llama/llama_index/blob/main/llama-index-packs/llama-index-packs-raptor/llama_index/packs/raptor/clustering.py
